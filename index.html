<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <link href='https://fonts.googleapis.com/css?family=Chivo:900' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-dark.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <title>SPARK-facedetection by spark-facedetection</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.1.6/Chart.js"></script>
  </head>

  <body>
    <div id="container">
      <div class="inner">

        <header>
          <h1>SPARK-facedetection</h1>
          <h2>Scalability, Pricing And Robustness benchmarK for face detection</h2>
        </header>

        <section id="downloads" class="clearfix">
          <a href="https://github.com/spark-facedetection" id="view-on-github" class="button"><span>View on GitHub</span></a>
        </section>

        <hr>

        <section id="main_content">
          

<h3>
<a id="description" class="anchor" href="#description" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Description</h3>

<p>Existing benchmarks for face detection in the wild (in unconstrained settings), e.g.
<a href="http://vis-www.cs.umass.edu/fddb/results.html">FDDB</a> and <a href="http://www.cbsr.ia.ac.cn/faceevaluation/results.html">MALF</a>,
assess the true positive rate (TPR) of face detection methods relative to each other.
On the other hand, neither is there a benchmark for face detection in the lab (in constrained settings)
that constrains the TPR and assesses the scalability and robustness,
nor is there a benchmark for face detection in the purchasing process
that constrains the TPR, scalability and robustness then assesses the pricing.
The benchmark for face detection in the lab assesses
the scalability on the number of detected faces (true positives) and
the robustness against small face size, yaw/pitch/roll, facial expression, occlusion, shadow.
This is to date</p>

<ol>
<li>the most comprehensive collection of benchmarks for face detection in the lab and in the purchasing process (8 benchmarks), and</li>
<li>the most comprehensive list of commercialized face detection (total 62).</li>
</ol>

<p>This could benefit face detection buyers' buying decision process and cost&ndash;benefit analysis.</p>

<h3>
<a id="results" class="anchor" href="#results" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Results</h3>

<canvas id="yaw" width="400" height="400"></canvas><br>
<script>
var ctx = document.getElementById("yaw");
var myChart = new Chart(ctx, {
    type: 'horizontalBar',
    data: {
        labels: ['Affectiva'],
        datasets: [
            {
                label: "Maximum ±Degree of Yaw",
                backgroundColor: 'rgba(255, 99, 132, 0.2)',
                borderColor: 'rgba(255, 99, 132, 1)',
                borderWidth: 1,
                data: [25]
            },
            {
                label: "Pitch",
                backgroundColor: 'rgba(255, 206, 86, 0.2)',
                borderColor: 'rgba(255, 206, 86, 1)',
                borderWidth: 1,
                data: [25]
            },
            {
                label: "Roll",
                backgroundColor: 'rgba(75, 192, 192, 0.2)',
                borderColor: 'rgba(75, 192, 192, 1)',
                borderWidth: 1,
                data: [25]
            },
        ]
    },
    options: {
        title: {
            display: true,
            text: 'Robustness against Yaw/Pitch/Roll Claimed by the Providers'
        },
        scales: {
            yAxes: [{
                ticks: {
                    beginAtZero:true
                }
            }]
        }
    }
});
</script>

<canvas id="one_time_fee" width="400" height="400"></canvas><br>
<script>
var ctx = document.getElementById("one_time_fee");
var myChart = new Chart(ctx, {
    type: 'horizontalBar',
    data: {
        labels: ["Ayonix", "Noldus", "Eyedea (Plan A)", "Eyedea (Plan B)", "Eyedea (Plan C)", "Eyedea (Plan D)", "Tastenkunst", "Baidu",
        "CCV", "CLandmark", "Deep Face Representation", "Dlib", "FaceRect", "libface", "libfacedetection", "M. Hammond", "OpenBR",
        "OpenCV", "OpenFace", "OpenIMAJ", "Semantic Vision Tech.", "Visual Geometry Group"],
        datasets: [{
            label: 'One-time Fee (USD)',
            data: [25000, 7434.024, 1919.50, 1886.54, 1032.19, 998.79, 2.22, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            backgroundColor: [
                'rgba(255, 99, 132, 0.2)',
                'rgba(54, 162, 235, 0.2)',
                'rgba(255, 206, 86, 0.2)',
                'rgba(75, 192, 192, 0.2)',
                'rgba(153, 102, 255, 0.2)',
                'rgba(255, 159, 64, 0.2)',
                'rgba(255, 99, 132, 0.2)',
                'rgba(54, 162, 235, 0.2)',
                'rgba(255, 206, 86, 0.2)',
                'rgba(75, 192, 192, 0.2)',
                'rgba(153, 102, 255, 0.2)',
                'rgba(255, 159, 64, 0.2)',
                'rgba(255, 99, 132, 0.2)',
                'rgba(54, 162, 235, 0.2)',
                'rgba(255, 206, 86, 0.2)',
                'rgba(75, 192, 192, 0.2)',
                'rgba(153, 102, 255, 0.2)',
                'rgba(255, 159, 64, 0.2)',
                'rgba(255, 99, 132, 0.2)',
                'rgba(54, 162, 235, 0.2)',
                'rgba(255, 206, 86, 0.2)',
                'rgba(75, 192, 192, 0.2)'
            ],
            borderColor: [
                'rgba(255,99,132,1)',
                'rgba(54, 162, 235, 1)',
                'rgba(255, 206, 86, 1)',
                'rgba(75, 192, 192, 1)',
                'rgba(153, 102, 255, 1)',
                'rgba(255, 159, 64, 1)',
                'rgba(255,99,132,1)',
                'rgba(54, 162, 235, 1)',
                'rgba(255, 206, 86, 1)',
                'rgba(75, 192, 192, 1)',
                'rgba(153, 102, 255, 1)',
                'rgba(255, 159, 64, 1)',
                'rgba(255,99,132,1)',
                'rgba(54, 162, 235, 1)',
                'rgba(255, 206, 86, 1)',
                'rgba(75, 192, 192, 1)',
                'rgba(153, 102, 255, 1)',
                'rgba(255, 159, 64, 1)',
                'rgba(255,99,132,1)',
                'rgba(54, 162, 235, 1)',
                'rgba(255, 206, 86, 1)',
                'rgba(75, 192, 192, 1)'
            ],
            borderWidth: 1
        }]
    },
    options: {
        title: {
            display: true,
            text: 'One-time Fee'
        },
        scales: {
            yAxes: [{
                ticks: {
                    beginAtZero:true
                }
            }]
        }
    }
});
</script>

<canvas id="monthly_fee" width="400" height="400"></canvas><br>
<script>
var ctx = document.getElementById("monthly_fee");
var myChart = new Chart(ctx, {
    type: 'horizontalBar',
    data: {
        labels: ["PUX", "Lambda Labs (Mega)", "Kairos (Enterprise)", "Kairos (Starter)", "Lambda Labs (Ultra)", "Affectiva", "Meerkat (Pro)", "Lambda Labs (Pro)",
          "SkyBiometry (P2)", "Meerkat (Standard)", "SkyBiometry (P1)", "Eyedea (Plan E)", "Eyedea (Plan F)", "Eyedea (Plan G)", "Eyedea (Plan H)",
          "Eyedea (Plan I)", "Eyedea (Plan J)", "Kairos (Trial)", "Lambda Labs (Basic)", "SkyBiometry (Free)"],
        datasets: [{
            label: 'Monthly Fee (USD/month)',
            data: [2500, 1449, 1000, 500, 449, 250, 245, 149, 110.96, 72, 55.47, 36.92, 34.14, 32.34, 30.95, 21.19, 18.41, 0, 0, 0],
            backgroundColor: [
                'rgba(255, 99, 132, 0.2)',
                'rgba(54, 162, 235, 0.2)',
                'rgba(255, 206, 86, 0.2)',
                'rgba(75, 192, 192, 0.2)',
                'rgba(153, 102, 255, 0.2)',
                'rgba(255, 159, 64, 0.2)',
                'rgba(255, 99, 132, 0.2)',
                'rgba(54, 162, 235, 0.2)',
                'rgba(255, 206, 86, 0.2)',
                'rgba(75, 192, 192, 0.2)',
                'rgba(153, 102, 255, 0.2)',
                'rgba(255, 159, 64, 0.2)',
                'rgba(255, 99, 132, 0.2)',
                'rgba(54, 162, 235, 0.2)',
                'rgba(255, 206, 86, 0.2)',
                'rgba(75, 192, 192, 0.2)',
                'rgba(153, 102, 255, 0.2)'
            ],
            borderColor: [
                'rgba(255,99,132,1)',
                'rgba(54, 162, 235, 1)',
                'rgba(255, 206, 86, 1)',
                'rgba(75, 192, 192, 1)',
                'rgba(153, 102, 255, 1)',
                'rgba(255, 159, 64, 1)',
                'rgba(255,99,132,1)',
                'rgba(54, 162, 235, 1)',
                'rgba(255, 206, 86, 1)',
                'rgba(75, 192, 192, 1)',
                'rgba(153, 102, 255, 1)',
                'rgba(255, 159, 64, 1)',
                'rgba(255,99,132,1)',
                'rgba(54, 162, 235, 1)',
                'rgba(255, 206, 86, 1)',
                'rgba(75, 192, 192, 1)',
                'rgba(153, 102, 255, 1)'
            ],
            borderWidth: 1
        }]
    },
    options: {
        title: {
            display: true,
            text: 'Monthly Fee'
        },
        scales: {
            yAxes: [{
                ticks: {
                    beginAtZero:true
                }
            }]
        }
    }
});
</script>

<canvas id="transaction_fee" width="400" height="400"></canvas>
<script>
var ctx = document.getElementById("transaction_fee");
var myChart = new Chart(ctx, {
    type: 'horizontalBar',
    data: {
        labels: ["Stupefix", "Google (1,001–1 million transactions / month)", "Google (1,000,001–5 million transactions / month)",
        "Microsoft (> 30,000 transactions / month)", "Google (5,000,001–20 million transactions / month)", "Google (1–1,000 transactions / month)",
        "Microsoft (1–30,000 transactions / month)"],
        datasets: [{
            label: 'Transaction Fee (USD / 1000 transactions)',
            data: [20, 2.5, 1.5, 1.5, 0.6, 0, 0],
            backgroundColor: [
                'rgba(255, 99, 132, 0.2)',
                'rgba(54, 162, 235, 0.2)',
                'rgba(255, 206, 86, 0.2)',
                'rgba(75, 192, 192, 0.2)',
                'rgba(153, 102, 255, 0.2)',
                'rgba(255, 159, 64, 0.2)',
                'rgba(255, 99, 132, 0.2)',
                'rgba(54, 162, 235, 0.2)',
                'rgba(255, 206, 86, 0.2)',
                'rgba(75, 192, 192, 0.2)',
                'rgba(153, 102, 255, 0.2)',
                'rgba(255, 159, 64, 0.2)',
                'rgba(255, 99, 132, 0.2)',
                'rgba(54, 162, 235, 0.2)',
                'rgba(255, 206, 86, 0.2)',
                'rgba(75, 192, 192, 0.2)',
                'rgba(153, 102, 255, 0.2)'
            ],
            borderColor: [
                'rgba(255,99,132,1)',
                'rgba(54, 162, 235, 1)',
                'rgba(255, 206, 86, 1)',
                'rgba(75, 192, 192, 1)',
                'rgba(153, 102, 255, 1)',
                'rgba(255, 159, 64, 1)',
                'rgba(255,99,132,1)',
                'rgba(54, 162, 235, 1)',
                'rgba(255, 206, 86, 1)',
                'rgba(75, 192, 192, 1)',
                'rgba(153, 102, 255, 1)',
                'rgba(255, 159, 64, 1)',
                'rgba(255,99,132,1)',
                'rgba(54, 162, 235, 1)',
                'rgba(255, 206, 86, 1)',
                'rgba(75, 192, 192, 1)',
                'rgba(153, 102, 255, 1)'
            ],
            borderWidth: 1
        }]
    },
    options: {
        title: {
            display: true,
            text: 'Transaction Fee'
        },
        scales: {
            yAxes: [{
                ticks: {
                    beginAtZero:true
                }
            }]
        }
    }
});
</script>

<h3>
<a id="reference" class="anchor" href="#reference" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Reference</h3>

<p>Wei-Lin Wang and Jen-Hui Chuang, "SPARK: scalability, pricing and robustness benchmark for face detection,"
<em>Technical Report, Dept. of Computer Science, National Chiao Tung University, Taiwan</em>, 2016.</p>
<!--I don't abbreviate our forename in the reference since the website has no space limitation like that of the conference papers.-->

<p>BibTeX entry:</p>

<pre><code>@TechReport{wang16,
  author      = {Wei-Lin Wang and Jen-Hui Chuang},
  title       = {{SPARK}: scalability, pricing and robustness benchmark for face detection},
  institution = {Dept. of Computer Science, National Chiao Tung University},
  address     = {Taiwan},
  year        = {2016},
}
</code></pre>

<p>Citing is caring <g-emoji alias="+1" fallback-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f44d.png">👍</g-emoji></p>

<h3>
<a id="contact" class="anchor" href="#contact" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contact</h3>

<p>Wei-Lin Wang - <a href="mailto:weblinkwang@gmail.com">weblinkwang@gmail.com</a></p>

<h3>
<a id="resources" class="anchor" href="#resources" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Resources</h3>

<p>Standalone face detection software (total 55):
<a href="http://www.acsysbiometrics.com/">Acsys</a>,
<a href="http://www.affectiva.com/solutions/apis-sdks/">Affectiva</a>,
<a href="http://chenlab.ece.cornell.edu/projects/FaceTracking/">AMP Lab</a>,
<a href="https://developers.google.com/vision/">Android</a>,
<a href="http://www.facerec.com/">Aurola</a>,
<a href="http://www.authenmetric.com/">AuthenMetric</a>,
<a href="http://www.aware.com/biometrics/nexa-face/#nexa-face">Aware</a>,
<a href="http://ayonix.com/products/ayonix-faceid-sdk/">Ayonix</a>,
<a href="https://www.bayometric.com/nitgen-nac-5000-face-fingerprint-access-control-system/">Bayometric</a>,
<a href="http://www.betaface.com/">Betaface</a>,
<a href="http://libccv.org/">CCV</a>,
<a href="http://cmp.felk.cvut.cz/%7Euricamic/clandmark/">CLandmark</a>,
<a href="http://www.cloudwalk.cn/">CloudWalk</a>,
<a href="http://www.cognitec.com/">Cognitec</a>,
<a href="http://www.colorreco.com/">ColorReco</a>,
<a href="http://face.ci2cv.net/">CI2CV</a>,
<a href="https://github.com/AlfredXiangWu/face_verification_experiment">Deep Face Representation</a>,
<a href="http://blog.dlib.net/2014/02/dlib-186-released-make-your-own-object.html">Dlib</a>,
<a href="http://www.eyedea.cz/">Eyedea</a>,
<a href="http://emovu.com/e/developers/">Eyeris</a>,
<a href="http://www.faceplusplus.com/">Face++</a>,
<a href="http://www.faceall.cn/">Faceall</a>,
<a href="http://www.facefirst.com/">FaceFirst</a>,
<a href="http://tech.facephi.com/en/">FacePhi</a>,
<a href="http://www.face-tek.com/e_product.php">Face-Tek</a>,
<a href="http://www.facevisa.com/">Facevisa</a>,
<a href="http://facewaretech.com/products/software/analyzer/">Faceware</a>,
<a href="http://people.kyb.tuebingen.mpg.de/kienzle/facedemo/facedemo.htm">Fdlib</a>,
<a href="http://www.iis.fraunhofer.de/en/ff/bsy/dl/shore.html">Fraunhofer IIS</a>,
<a href="http://facesdk.eu/">Imacondis</a>,
<a href="http://vision.sysu.edu.cn/systems/surveillance/">IMC Lab</a>,
<a href="http://www.insky.so/">Insky</a>,
<a href="https://msdn.microsoft.com/en-us/library/jj130970.aspx">Kinect</a>,
<a href="http://libface.sourceforge.net/">libface</a>,
<a href="https://github.com/ShiqiYu/libfacedetection">libfacedetection</a>,
<a href="https://www.linkface.cn/">Linkface API</a>,
<a href="http://www.luxand.com/facesdk/">Luxand</a>,
<a href="https://github.com/mc-jesus/face_detect_n_track">M. Hammond</a>,
<a href="http://www.neurotechnology.com/verilook.html">Neurotechnology</a>,
<a href="http://www.noldus.com/facereader/facereader-api">Noldus</a>,
<a href="http://www.mathworks.com/matlabcentral/fileexchange/29834-face-detection-using-support-vector-machine--svm-">O. Sakhi</a>,
<a href="http://openbiometrics.org/">OpenBR</a>,
<a href="http://opencv.org/">OpenCV</a>,
<a href="https://cmusatyalab.github.io/openface/">OpenFace</a>,
<a href="http://www.openimaj.org/">OpenIMAJ</a>,
<a href="http://products.suntektech.com/products/intelligent-security/content20140605001/index.jsp?catid=223%7C322&amp;id=359">pci-suntektech</a>,
<a href="http://360biometrics.com/face-recognition.php">PersonID</a>,
<a href="http://pux.co.jp/en/product/softsensor-en/faceu/">PUX</a>,
<a href="http://www.semanticvisiontech.com/">Semantic Vision Tech.</a>,
<a href="https://sites.google.com/site/sibtulhussain/code">S. Hussain</a>,
<a href="http://sightcorp.com/crowdsight/">Sightcorp</a>,
<a href="http://www.tastenkunst.com/">Tastenkunst</a>,
<a href="http://www.tcit-us.com/">TCIT</a>,
<a href="http://www.tvplay.cn/index.php?m=content&amp;c=index&amp;a=lists&amp;catid=17">TVPlay</a>,
<a href="http://visagetechnologies.com/">Visage Tech.</a>,
<a href="http://www.robots.ox.ac.uk/%7Evgg/software/vgg_face/">Visual Geometry Group</a>,
<a href="https://msdn.microsoft.com/en-us/library/windows/hardware/mt450467(v=vs.85).aspx">Windows</a>,
<a href="http://research.microsoft.com/en-us/projects/facesdk/">Windows Phone</a>,
<a href="https://www.ics.uci.edu/%7Exzhu/face/">X. Zhu</a>.</p>

<p>Face detection web services (total 24):
<a href="http://www.allgovision.com/face-recognition.php">AllGo Embed. Sys.</a>,
<a href="http://www.authenmetric.com/">AuthenMetric</a>,
<a href="http://apistore.baidu.com/apiworks/servicedetail/464.html">Baidu</a>,
<a href="http://www.betafaceapi.com/">Betaface</a>,
<a href="https://playground.bioid.com/">BioID</a>,
<a href="http://www.cloudwalk.cn/">CloudWalk</a>,
<a href="http://emovu.com/e/developers/">Eyeris</a>,
<a href="http://www.faceplusplus.com/">Face++</a>,
<a href="http://www.faceall.cn/">Faceall</a>,
<a href="http://www.facerapp.com/">FaceR</a>,
<a href="http://apicloud.me/apis/facerect/demo/">FaceRect</a>,
<a href="http://www.facevisa.com/">Facevisa</a>,
<a href="https://cloud.google.com/vision/">Google</a>,
<a href="https://www.kairos.com/face-recognition-api">Kairos</a>,
<a href="https://developers.keylemon.com/documentation/reference">KeyLemon</a>,
<a href="http://www.lambdal.com/">Lambda Labs</a>,
<a href="https://www.linkface.cn/">Linkface SDK</a>,
<a href="http://www.meerkat.com.br/solution_fr.html">Meerkat</a>,
<a href="https://www.microsoft.com/cognitive-services/en-us/face-api">Microsoft</a>,
<a href="http://www.nviso.ch/">nViso</a>,
<a href="http://www.oddcast.com/dev/facedetectionAPI/">Oddcast</a>,
<a href="https://skybiometry.com/">SkyBiometry</a>,
<a href="https://developer.stupeflix.com/tasks/image.face/">Stupefix</a>,
<a href="https://open.youtu.qq.com/">Tencent</a>,
<a href="http://www.visionlabs.ru/">VisionLabs</a>.</p>

<p>Datasets and benchmarks:
<a href="https://data.vision.ee.ethz.ch/cvl/aess/dataset/">A. Ess</a>,
<a href="http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/">Caltech</a>,
<a href="http://vision.ucsd.edu/%7Eiskwak/ExtYaleDatabase/ExtYaleB.html">Ext. Yale B</a>,
<a href="http://vis-www.cs.umass.edu/fddb/">FDDB</a>,
<a href="http://pascal.inrialpes.fr/data/human/">INRIA</a>,
<a href="http://vis-www.cs.umass.edu/lfw/">LFW</a>,
<a href="http://www.cbsr.ia.ac.cn/faceevaluation/">MALF</a>,
<a href="https://sites.google.com/site/miirsurveillance/">MI3</a>,
<a href="http://robotics.csie.ncku.edu.tw/Databases/FaceDetect_PoseEstimate.htm">NCKU Robotics Lab</a>,
<a href="http://www-prima.inrialpes.fr/Pointing04/data-face.html">Pointing'04</a>,
<a href="http://www.scface.org/">SCface</a>,
<a href="http://atvs.ii.uam.es/scfacedb_landmarks.html">SCfaceDB</a>,
<a href="http://mmlab.ie.cuhk.edu.hk/projects/WIDERFace/">WIDER FACE</a>.</p>

<h3>
<a id="references" class="anchor" href="#references" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>References</h3>

<!--I don't abbreviate the authors' forename in the reference since the website has no space limitation like that of the conference papers.-->
<p>Vidit Jain and Erik Learned-Miller, "FDDB: A Benchmark for Face Detection in Unconstrained Settings,"
<em>Technical Report UM-CS-2010-009, Dept. of Computer Science, University of Massachusetts, Amherst</em>, 2010. </p>

<p>Bin Yang, Junjie Yan, Zhen Lei and Stan Z. Li., "Fine-grained Evaluation on Face Detection in the Wild,"
<em>Proceedings of the 11th IEEE International Conference on Automatic Face and Gesture Recognition Conference and Workshops</em>, 2015.</p>
        </section>

        <footer>
          This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.
          Tactile theme by <a href="https://twitter.com/jasonlong">Jason Long</a>.
          Charts produced using <a href="http://www.chartjs.org/">Chart.js</a>.
        </footer>

        
      </div>
    </div>
  </body>
</html>
